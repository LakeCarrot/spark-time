Spark Command: /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java -cp /home/dogtail/spark-1.4.1/sbin/../conf/:/home/dogtail/spark-1.4.1/assembly/target/scala-2.10/spark-assembly-1.4.1-hadoop2.c.jar:/home/dogtail/spark-1.4.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/dogtail/spark-1.4.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/dogtail/spark-1.4.1/lib_managed/jars/datanucleus-core-3.2.10.jar -Xms512m -Xmx512m -XX:MaxPermSize=256m org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://master:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/02/19 22:40:14 INFO Worker: Registered signal handlers for [TERM, HUP, INT]
16/02/19 22:40:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/02/19 22:40:14 INFO SecurityManager: Changing view acls to: dogtail
16/02/19 22:40:14 INFO SecurityManager: Changing modify acls to: dogtail
16/02/19 22:40:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(dogtail); users with modify permissions: Set(dogtail)
16/02/19 22:40:15 INFO Slf4jLogger: Slf4jLogger started
16/02/19 22:40:15 INFO Remoting: Starting remoting
16/02/19 22:40:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkWorker@172.28.143.112:42632]
16/02/19 22:40:15 INFO Utils: Successfully started service 'sparkWorker' on port 42632.
16/02/19 22:40:15 INFO Worker: Starting Spark worker 172.28.143.112:42632 with 4 cores, 6.7 GB RAM
16/02/19 22:40:15 INFO Worker: Running Spark version 1.4.1
16/02/19 22:40:15 INFO Worker: Spark home: /home/dogtail/spark-1.4.1
16/02/19 22:40:15 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
16/02/19 22:40:15 INFO WorkerWebUI: Started WorkerWebUI at http://172.28.143.112:8081
16/02/19 22:40:15 INFO Worker: Connecting to master akka.tcp://sparkMaster@master:7077/user/Master...
16/02/19 22:40:15 INFO Worker: Successfully registered with master spark://master:7077
16/02/19 22:40:34 INFO Worker: Asked to launch executor app-20160219224034-0000/1 for SparseNaiveBayes with Params(hdfs://172.28.143.191:9000/HiBench/Bayes/Input,100,-1,1.0)
16/02/19 22:40:34 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java" "-cp" "/home/dogtail/spark-1.4.1/sbin/../conf/:/home/dogtail/spark-1.4.1/assembly/target/scala-2.10/spark-assembly-1.4.1-hadoop2.c.jar:/home/dogtail/spark-1.4.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/home/dogtail/spark-1.4.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/dogtail/spark-1.4.1/lib_managed/jars/datanucleus-core-3.2.10.jar" "-Xms6144M" "-Xmx6144M" "-Dspark.driver.port=49043" "-XX:MaxPermSize=256m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@172.28.143.191:49043/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "172.28.143.112" "--cores" "4" "--app-id" "app-20160219224034-0000" "--worker-url" "akka.tcp://sparkWorker@172.28.143.112:42632/user/Worker"
16/02/19 22:56:39 INFO Worker: Asked to kill executor app-20160219224034-0000/1
16/02/19 22:56:40 INFO ExecutorRunner: Runner thread for executor app-20160219224034-0000/1 interrupted
16/02/19 22:56:40 INFO ExecutorRunner: Killing process!
16/02/19 22:56:40 ERROR FileAppender: Error writing stream to file /home/dogtail/spark-1.4.1/work/app-20160219224034-0000/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1772)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
16/02/19 22:56:41 INFO Worker: Executor app-20160219224034-0000/1 finished with state KILLED exitStatus 143
16/02/19 22:56:41 INFO Worker: Cleaning up local directories for application app-20160219224034-0000
16/02/19 22:56:41 WARN ReliableDeliverySupervisor: Association with remote system [akka.tcp://sparkExecutor@172.28.143.112:59851] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
16/02/20 15:46:46 ERROR Worker: RECEIVED SIGNAL 15: SIGTERM
16/02/20 15:46:46 INFO Utils: Shutdown hook called
16/02/20 15:46:46 INFO Utils: Deleting directory /tmp/spark-227e6241-240e-4396-84d1-c58ae4ad5dfe
